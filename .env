# model
MODEL_PATH=./models
MODEL_NAME=DeepSeek-R1-Distill-Qwen-1.5B-Q4_K_M.gguf

# llama.cpp
CUDA_VERSION=12.6.0
UBUNTU_VERSION=22.04

# MixEval
## judge
FREEFORM_JUDGE=llamacpp
MULTICHOICE_JUDGE=llamacpp
API_BASE_URL=http://llamacpp:8000/v1
API_PARALLEL_NUM=10
MODEL_PARSER_API=API_TOKEN
## benchmark
BENCHMARK=mixeval_hard
VERSION=2024-08-11
## runtime
BATCH_SIZE=20
MAX_GPU_MEMORY=16GiB
OUTPUT_DIR=./model_responses/
